{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import betabinom\n",
    "\n",
    "\n",
    "def compute_beta(alpha, n, mean):\n",
    "    return (1-mean/n) / (mean/n) * alpha\n",
    "\n",
    "\n",
    "def compute_alpha(n, mean, variance):\n",
    "    ratio = (1-mean/n) / (mean/n)\n",
    "    alpha = ((1+ratio)**2 * variance - n**2 * ratio) / (n*ratio*(1+ratio) - variance* (1 + ratio)**3)\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(19680801)\n",
    "\n",
    "    # example data\n",
    "    n = 30  # Size of the support (i.e. numbers between 0 and n)\n",
    "    mu = 10  # mean of distribution\n",
    "    sigma = 4  # standard deviation of distribution\n",
    "    \n",
    "    # Compute the alpha and beta for the given mu and sigma\n",
    "    alpha = compute_alpha(n , mu, sigma**2)\n",
    "    beta = compute_beta(alpha, n, mu)\n",
    "    \n",
    "    x = betabinom.rvs(n, alpha, beta, size=100000)\n",
    "\n",
    "    num_bins = n+1\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # the histogram of the data\n",
    "    n, bins, patches = ax.hist(x, num_bins, density=True)\n",
    "\n",
    "    ax.set_xlabel('Number of outliers')\n",
    "    ax.set_ylabel('Probability density')\n",
    "    ax.set_title(r'Histogram of Beta-binominal dist: $\\mu=8$, $\\sigma=4$')\n",
    "\n",
    "    # Tweak spacing to prevent clipping of ylabel\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/home/rohit/PhD_Work/GM_my_version/Graph_matching/\")\n",
    "import argparse\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import slam.plot as splt\n",
    "import slam.topology as stop\n",
    "import slam.generate_parametric_surfaces as sgps\n",
    "import trimesh\n",
    "import os\n",
    "import tools.graph_processing as gp\n",
    "from sphere import *\n",
    "from tqdm.auto import tqdm,trange\n",
    "from scipy.stats import betabinom\n",
    "import random\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sphere_random_sampling(vertex_number=100, radius=1.0):\n",
    "    \"\"\"\n",
    "\tgenerate a sphere with random sampling\n",
    "\t:param vertex_number: number of vertices in the output spherical mesh\n",
    "\t:param radius: radius of the output sphere\n",
    "\t:return:\n",
    "\t\"\"\"\n",
    "    coords = np.zeros((vertex_number, 3))\n",
    "    for i in range(vertex_number):\n",
    "        M = np.random.normal(size=(3, 3))\n",
    "        Q, R = np.linalg.qr(M)\n",
    "        coords[i, :] = Q[:, 0].transpose() * np.sign(R[0, 0])\n",
    "    if radius != 1:\n",
    "        coords = radius * coords\n",
    "    return coords\n",
    "\n",
    "def tri_from_hull(vertices):\n",
    "    \"\"\"\n",
    "\tcompute faces from vertices using trimesh convex hull\n",
    "\t:param vertices: (n, 3) float\n",
    "\t:return:\n",
    "\t\"\"\"\n",
    "    mesh = trimesh.Trimesh(vertices=vertices, process=False)\n",
    "    return mesh.convex_hull\n",
    "\n",
    "\n",
    "def edge_len_threshold(graph,thr): # Adds a percentage of edges \n",
    "    \n",
    "    edge_to_add = random.sample(list(graph.edges),round(len(graph.edges)*thr))\n",
    "\n",
    "    return edge_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_beta(alpha, n, mean):\n",
    "    return (1-mean/n) / (mean/n) * alpha\n",
    "\n",
    "\n",
    "def compute_alpha(n, mean, variance):\n",
    "    ratio = (1-mean/n) / (mean/n)\n",
    "    alpha = ((1+ratio)**2 * variance - n**2 * ratio) / (n*ratio*(1+ratio) - variance* (1 + ratio)**3)\n",
    "    return alpha\n",
    "\n",
    "\n",
    "def generate_nb_outliers_and_nb_supress(nb_vertices):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Sample nb_outliers and nb_supress from a Normal dist\n",
    "    following the std of real data\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    mean_real_data = 10         # mean real data\n",
    "    std_real_data = 4           # std real data\n",
    "\n",
    "\n",
    "    mu = 10 # mu_A = mu_B = mu\n",
    "    sigma = std_real_data\n",
    "    n = 20\n",
    "\n",
    "    alpha = compute_alpha(n , mu, sigma**2)  # corresponding alpha with respect to given mu and sigma\n",
    "    beta = compute_beta(alpha, n, mu)       # corresponding beta\n",
    "\n",
    "    nb_supress = betabinom.rvs(n, alpha, beta, size=1)[0]\n",
    "    nb_outliers = betabinom.rvs(n, alpha, beta, size=1)[0]                 # Sample nb_outliers\n",
    "\n",
    "\n",
    "    return int(nb_outliers),int(nb_supress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noisy_graph(original_graph, nb_vertices, sigma_noise_nodes=1400, sigma_noise_edges=1,\n",
    "                         radius=100):\n",
    "    # Perturbate the coordinates\n",
    "\n",
    "    noisy_coord = []\n",
    "    key = []\n",
    "    value = []\n",
    "    nb_outliers = 0\n",
    "    nb_supress = 0\n",
    "\n",
    "    for index in range(nb_vertices):\n",
    "        # Sampling from Von Mises - Fisher distribution\n",
    "        original_coord = original_graph.nodes[index][\"coord\"]\n",
    "        mean_original = original_coord / np.linalg.norm(original_coord)  # convert to mean unit vector.\n",
    "        noisy_coordinate = Sphere().sample(1, distribution='vMF', mu=mean_original,\n",
    "                                           kappa=sigma_noise_nodes).sample[0]\n",
    "\n",
    "        noisy_coordinate = noisy_coordinate * np.linalg.norm(original_coord) # rescale to original size.\n",
    "        # print(noisy_coordinate)\n",
    "        noisy_coord.append(noisy_coordinate)\n",
    "\n",
    "        print(original_coord,\" \",noisy_coordinate)\n",
    "\n",
    "\n",
    "    nb_outliers, nb_supress = generate_nb_outliers_and_nb_supress(nb_vertices)  # Sample nb_outliers and nb_supress\n",
    "    #nb_outliers = 0\n",
    "    \n",
    "    noisy_coord_all = noisy_coord\n",
    "    \n",
    "\n",
    "    #Supress Non-Outlier nodes\n",
    "    if nb_supress > 0:\n",
    "        \n",
    "        supress_list = random.sample(range(len(noisy_coord)), nb_supress) # Indexes to remove \n",
    "        \n",
    "        removed_coords = [noisy_coord[i] for i in range(len(noisy_coord)) if i in supress_list]\n",
    "        \n",
    "        #noisy_coord = [dummy_coords if i in supress_list else noisy_coord[i] for i in range(len(noisy_coord))]\n",
    "        \n",
    "        noisy_coord = [noisy_coord[i] for i in range(len(noisy_coord)) if i not in supress_list]\n",
    "        \n",
    "        print(\"nb_supress : \",nb_supress)\n",
    "        \n",
    "    print(\"nb_outliers : \",nb_outliers)\n",
    "        \n",
    "            \n",
    "    #print('Noisy coord len after supression',len(noisy_coord_all))\n",
    "    #print('removed coord len after supression',len(removed_coords))\n",
    "\n",
    "\n",
    "    # Add Outliers\n",
    "    sphere_random_sampling = []\n",
    "    if nb_outliers > 0:\n",
    "        #print(\"nb_outliers: \", nb_outliers)\n",
    "\n",
    "        sphere_random_sampling = generate_sphere_random_sampling(vertex_number=nb_outliers, radius=radius)\n",
    "        # merge pertubated and outlier coordinates to add edges \n",
    "        all_coord = noisy_coord + list(sphere_random_sampling)\n",
    "    else:\n",
    "        all_coord = noisy_coord\n",
    "\n",
    "\n",
    "    noisy_graph = nx.Graph()\n",
    "\n",
    "    compute_noisy_edges = tri_from_hull(all_coord)  # take all peturbated coord and comp conv hull.\n",
    "    adja = stop.adjacency_matrix(compute_noisy_edges)  # compute the new adjacency mat.\n",
    "\n",
    "    noisy_graph = nx.from_numpy_matrix(adja.todense())\n",
    "    \n",
    "\n",
    "    node_attribute_dict = {}\n",
    "    for node in noisy_graph.nodes():\n",
    "        node_attribute_dict[node] = {\"coord\": np.array(compute_noisy_edges.vertices[node]),'is_dummy':False}\n",
    "        \n",
    "#     dummy_nodes = [j for j in range(len(noisy_graph.nodes), len(noisy_graph.nodes) + len(supress_list))] \n",
    "#     noisy_graph.add_nodes_from(dummy_nodes,is_dummy=True) # add dummy nodes\n",
    "    \n",
    "        \n",
    "    nx.set_node_attributes(noisy_graph, node_attribute_dict)\n",
    "    nx.set_edge_attributes(noisy_graph, 1.0, name=\"weight\")\n",
    "\n",
    "    \n",
    "    edge_attribute_dict = {}\n",
    "    id_counter = 0  # useful for affinity matrix caculation\n",
    "    for edge in noisy_graph.edges:\n",
    "        # We calculate the geodesic distance\n",
    "        end_a = noisy_graph.nodes()[edge[0]][\"coord\"]\n",
    "        end_b = noisy_graph.nodes()[edge[1]][\"coord\"]\n",
    "        geodesic_dist = gp.compute_geodesic_distance_sphere(end_a, end_b, radius)\n",
    "\n",
    "        # add the information in the dictionnary\n",
    "        edge_attribute_dict[edge] = {\"geodesic_distance\": geodesic_dist, \"id\": id_counter}\n",
    "        id_counter += 1\n",
    "\n",
    "    # add the edge attributes to the graph\n",
    "    nx.set_edge_attributes(noisy_graph, edge_attribute_dict)\n",
    "\n",
    "    # Extracting the ground-truth correspondence\n",
    "\n",
    "    \n",
    "    ground_truth_permutation = []\n",
    "    counter = 0\n",
    "    check = False\n",
    "#     print(dummy_nodes)\n",
    "    \n",
    "    for i in range(len(noisy_graph.nodes)): \n",
    "        for j in range(len(noisy_coord_all)):  # upto the indexes of outliers\n",
    "            if np.linalg.norm(noisy_coord_all[j] - noisy_graph.nodes[i]['coord']) == 0.:\n",
    "                ground_truth_permutation.append(j)\n",
    "                continue\n",
    "                \n",
    "            elif j == len(noisy_coord_all) - 1.:\n",
    "                 for outlier in sphere_random_sampling:\n",
    "                        if np.linalg.norm(outlier - noisy_graph.nodes[i]['coord']) == 0.:\n",
    "                            ground_truth_permutation.append('O')\n",
    "          \n",
    "        \n",
    "#         if check == False:\n",
    "#             print(counter)\n",
    "            \n",
    "#             if dummy_nodes[counter] >= len(noisy_coord_all):\n",
    "#                 key.append(i)\n",
    "#             ground_truth_permutation.append(dummy_nodes[counter])#add idx of dummy node as correspondence\n",
    "#             counter += 1\n",
    "#         check = False\n",
    "                \n",
    "            \n",
    "\n",
    "#     for outlier in sphere_random_sampling:\n",
    "#         for i in range(len(all_coord)):\n",
    "#             if np.mean(noisy_graph.nodes[i]['coord']) == np.mean(outlier):\n",
    "#                 if i<nb_vertices:\n",
    "#                     value.append(i)\n",
    "\n",
    "\n",
    "#     if nb_outliers > 0 and len(key)!=0:\n",
    "#         index = 0\n",
    "#         for j in range(len(ground_truth_permutation)):\n",
    "#             if ground_truth_permutation[j] == key[index]:\n",
    "#                 ground_truth_permutation[j] = value[index]\n",
    "#                 index+=1\n",
    "#                 if index == len(key):\n",
    "#                     break\n",
    "\n",
    "#         key = key + value\n",
    "#         value = value + key\n",
    "\n",
    "#         mapping = dict(zip(key,value))\n",
    "#         #print(\"mapping :\",mapping)\n",
    "#         #print(\"number of nodes in graphs: \", len(noisy_graph.nodes))\n",
    "#         noisy_graph = nx.relabel_nodes(noisy_graph, mapping)\n",
    "\n",
    "\n",
    "    # Remove 10% of random edges\n",
    "#     edge_to_remove = edge_len_threshold(noisy_graph, 0.10)\n",
    "#     noisy_graph.remove_edges_from(edge_to_remove)\n",
    "\n",
    "#     noisy_graph.remove_edges_from(nx.selfloop_edges(noisy_graph))\n",
    "\n",
    "\n",
    "    return ground_truth_permutation, noisy_graph,noisy_coord_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_graphs= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_graph = nx.read_gpickle('reference_1.gpickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 20.96346116 -76.88340545 -60.41088695]   [ 21.91153331 -78.10018138 -58.4828725 ]\n",
      "[-40.38208717  36.61107826  83.83863062]   [-39.54973069  35.81698238  84.57518889]\n",
      "[-53.14616772  26.3147491  -80.51719591]   [-49.41083369  22.79019218 -83.89980128]\n",
      "[87.30901573 46.98534633 13.01971589]   [87.90662198 46.27881099 11.43229917]\n",
      "[-50.93066397  85.66396199  -8.23122617]   [-51.30180719  84.49625018 -15.11649051]\n",
      "[-85.9712732   50.983334    -3.10480883]   [-85.37276984  52.06316105   0.95782591]\n",
      "[-83.8724879  -23.10325171 -49.31171803]   [-84.76034527 -23.8737726  -47.38910055]\n",
      "[ -8.14699669  97.86962485 -18.84576812]   [-10.00621013  96.9414696  -22.41042684]\n",
      "[-90.38310799  25.9637659   34.01141941]   [-88.79359349  29.39867894  35.37535064]\n",
      "[ 2.31108465 83.28236347 55.30557678]   [ 2.72444962 81.90503131 57.30744473]\n",
      "[84.6487079  14.32457521 51.27770271]   [84.93741475 14.36852202 50.78563921]\n",
      "[ 81.88240267 -57.22654565   4.51603881]   [ 81.17070132 -57.9376393    7.38560761]\n",
      "[ 20.71161998  32.4404267  -92.29651951]   [ 20.4184669   31.78021106 -92.59106001]\n",
      "[ 71.1577078   65.44426721 -25.56615945]   [ 72.3575313   65.1184683  -22.89045107]\n",
      "[-39.92334919 -43.92600033 -80.47752906]   [-39.02188659 -41.53107639 -82.17336589]\n",
      "[ 67.64475611 -64.17671898 -36.13219771]   [ 70.35443955 -64.42147507 -30.00210637]\n",
      "[ 37.35079912 -92.41109706  -8.06888744]   [ 37.74268232 -92.14406711  -9.2174198 ]\n",
      "[ 53.60484077 -23.35121063 -81.12485444]   [ 55.97766349 -24.84094519 -79.05332777]\n",
      "[-56.41173779  75.65470627  33.07689918]   [-58.17232667  75.12768266  31.17389465]\n",
      "[ 44.5827481  -72.2409887   52.85468875]   [ 49.82963337 -69.76524611  51.47638364]\n",
      "nb_supress :  9\n",
      "nb_outliers :  16\n"
     ]
    }
   ],
   "source": [
    "ground_truth_1, noisy_graph_1, noisy_coord_all_1 = generate_noisy_graph(ref_graph,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 3,\n",
       " 18,\n",
       " 'O',\n",
       " 11,\n",
       " 2,\n",
       " 10,\n",
       " 'O',\n",
       " 'O',\n",
       " 0,\n",
       " 'O',\n",
       " 19,\n",
       " 9,\n",
       " 8,\n",
       " 'O',\n",
       " 'O',\n",
       " 15,\n",
       " 13,\n",
       " 16,\n",
       " 14,\n",
       " 12,\n",
       " 4,\n",
       " 1,\n",
       " 'O',\n",
       " 17]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coord': array([ 21.97005517, -74.9252422 , -62.47819426]), 'is_dummy': False}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_graph_x.nodes[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coord': array([ 20.96346116, -76.88340545, -60.41088695])}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_graph.nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ground_truth_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_in_between_perm_matrix(perm_mat_1, perm_mat_2):\n",
    "    \"\"\"\n",
    "\tGiven two permutation from noisy graphs to a reference graph,\n",
    "\tReturn the permutation matrix to go from one graph to the other\n",
    "\t\"\"\"\n",
    "    result_perm = {}\n",
    "    for i in range(len(perm_mat_1)):\n",
    "        if perm_mat_1[i] == 'O':\n",
    "                continue\n",
    "        for j in range(len(perm_mat_2)):\n",
    "            if perm_mat_2[j] == 'O':\n",
    "                continue\n",
    "            \n",
    "            if perm_mat_1[i] == perm_mat_2[j]:\n",
    "                result_perm[i] = j\n",
    "\n",
    "    return result_perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_0 = ground_truth_0\n",
    "gt_1 = ground_truth_1\n",
    "# gt_2 = ground_truth_2\n",
    "# gt_3 = ground_truth_3\n",
    "gt_all = [gt_0,gt_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_groundtruth = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_perm = get_in_between_perm_matrix(gt_0,gt_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 7, 5: 6, 7: 17, 10: 22, 12: 14, 17: 26, 18: 19, 21: 16}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[87.96029962 43.95165181 18.19994488] ---- [87.90662198 46.27881099 11.43229917]\n",
      "[ 82.9968391  -55.77855793   0.52647356] ---- [ 81.17070132 -57.9376393    7.38560761]\n",
      "[82.64595281 17.32215314 53.56854949] ---- [84.93741475 14.36852202 50.78563921]\n",
      "[ 21.41644424 -77.66644408 -59.23900218] ---- [ 21.91153331 -78.10018138 -58.4828725 ]\n",
      "[ 47.52387721 -69.9761136   53.33689737] ---- [ 49.82963337 -69.76524611  51.47638364]\n",
      "[ 69.85966807 -62.38129156 -35.04570217] ---- [ 70.35443955 -64.42147507 -30.00210637]\n",
      "[ 69.83559898  66.13268484 -27.37621433] ---- [ 72.3575313   65.1184683  -22.89045107]\n",
      "[ 24.54262499  34.17415789 -90.71817068] ---- [ 20.4184669   31.78021106 -92.59106001]\n"
     ]
    }
   ],
   "source": [
    "for i,j in result_perm.items():\n",
    "    print(noisy_graph_0.nodes[i]['coord'],'----',noisy_graph_1.nodes[j]['coord'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_03 = {}\n",
    "\n",
    "for i in range(len(gt_0)):\n",
    "    for j in range(len(gt_3)):\n",
    "        if gt_0[i] == gt_3[j]:\n",
    "            gt_03[i] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_groundtruth = []\n",
    "new_groundtruth = [gt_00,gt_01,gt_02,gt_03]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_dict = {}\n",
    "\n",
    "for i in range(1):\n",
    "    for j in range(4):\n",
    "        ground_dict[str(i)+str(j)] =globals()['gt_'+str(i)+str(j)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,value in gt_02.items():\n",
    "    print(noisy_graph.nodes[key]['coord'],noisy_graph_2.nodes[value]['coord'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key,value in g3_dict.items():\n",
    "#     if value == -1:\n",
    "#         continue\n",
    "#     else:\n",
    "#         print(noisy_graph_3.nodes[key]['coord'],'-----',value,'----',noisy_graph.nodes[value]['coord'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ref_graph.nodes)):\n",
    "    print(ref_graph.nodes[i]['coord'],noisy_coord_all[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ref_graph.nodes)):\n",
    "    print(ref_graph.nodes[i]['coord'],noisy_coord_all_3[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.read_gpickle('test_graphs.gpickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.load('new_groundtruth.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graphs = [noisy_graph,noisy_graph_1,noisy_graph_2,noisy_graph_3]\n",
    "np.save('new_groundtruth.npy',new_groundtruth)\n",
    "nx.write_gpickle(test_graphs,'test_graphs.gpickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_graph_2.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('g3 node attr len: ',nx.get_node_attributes(g1,'label_gt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in enumerate(ground_truth_permutation):\n",
    "    print(noisy_graph.nodes[i]['coord'],noisy_coord_all[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shuffled_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_coord_all[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_graph.nodes[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in enumerate(ground_truth):\n",
    "    \n",
    "    if noisy_graph.nodes[j]['is_dummy'] == False:\n",
    "        \n",
    "        print(noisy_graph.nodes[j]['coord'],ref_graph.nodes[i]['coord'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = random.sample(range(10), 5)\n",
    "rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ground_truth[i] for i in range(len(ground_truth)) if i not in rm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ref_graph.nodes[i]['coord'] for i in range(len(ref_graph.nodes)) if i in rm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_coords = list(nx.get_node_attributes(ref_graph,'coord').values())\n",
    "\n",
    "dummy_coords = np.array([0.0,0.0,0.0])\n",
    "\n",
    "noisy_coords_2 = [dummy_coords if i in rm else noisy_coords[i] for i in range(len(noisy_coords))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.get_node_attributes(noisy_graph,'coord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noisy_graph.add_nodes_from([(13, {'is_dummy': True}),(14, {'is_dummy': True}),(15, {'is_dummy': True})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noisy_graph.add_node(16,is_dummy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in ground_truth:\n",
    "#     print(noisy_graph.nodes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = np.load('ground_truth.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_graph = \"./noise_1000,outliers_20/graphs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g0 = nx.read_gpickle(path_graph+'graph_12.gpickle')\n",
    "# g1 = nx.read_gpickle(path_graph+'graph_1.gpickle')\n",
    "# g8 = nx.read_gpickle(path_graph+'graph_8.gpickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_12 = {}\n",
    "\n",
    "# for i in range(len(gt_1)):\n",
    "#     for j in range(len(gt_2)):\n",
    "#         if gt_1[i] == gt_2[j]:\n",
    "#             gt_12[i] = j\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,j in gt_12.items():\n",
    "#     print(noisy_graph.nodes[i]['coord'], noisy_graph_1.nodes[j]['coord'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for i,j in enumerate(ground_truth_1):\n",
    "#     print(noisy_graph_1.nodes[i]['coord'],noisy_coord_all[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_updated = nx.read_gpickle('g_updated.gpickle')\n",
    "g1_updated = nx.read_gpickle('g1_updated.gpickle')\n",
    "g2_updated = nx.read_gpickle('g2_updated.gpickle')\n",
    "g3_updated = nx.read_gpickle('g3_updated.gpickle')\n",
    "\n",
    "\n",
    "\n",
    "g_values = nx.get_node_attributes(g1_updated,'label_gt').values()\n",
    "\n",
    "for i,j in enumerate(g_values):\n",
    "    \n",
    "    if(j == -1):\n",
    "        continue\n",
    "        \n",
    "    else:\n",
    "        print(g_updated.nodes[j]['coord'],g1_updated.nodes[i]['coord'])\n",
    "        print(g_updated.nodes[j]['label_gt'],'....',g1_updated.nodes[i]['label_gt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_graphs = [len(g_updated.nodes),len(g1_updated.nodes),len(g2_updated.nodes),len(g3_updated.nodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_graphs.index(min(list_graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_updated.nodes[4]['label_gt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_updated.nodes.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if there is -1 in attribute\n",
    "\n",
    "#number of nodes to add in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_label = list(nx.get_node_attributes(g1_updated,'label_gt').values())\n",
    "count_val = gt_label.count(-1)\n",
    "num_nodes_to_add = len(g_updated.nodes())-(len(g1_updated.nodes)-count_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(gt_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(g_updated.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_g1 = len(g1_updated.nodes)\n",
    "\n",
    "labels = list(set(list(g_updated.nodes)).symmetric_difference(set(gt_label)))\n",
    "\n",
    "if -1 in labels:\n",
    "    labels.remove(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in enumerate(labels):\n",
    "    \n",
    "    g1_updated.add_node(len_g1+i,label_gt=j,coord=[-0.0,-0.0,-0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(list(nx.get_node_attributes(g1_updated,'label_gt').values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dummy_for_visu(g,g1):\n",
    "    \n",
    "#     gt_label = list(nx.get_node_attributes(g1,'label_gt').values())\n",
    "    \n",
    "#     len_g1 = len(g1.nodes)\n",
    "\n",
    "    \n",
    "#     labels = list(set(list(g.nodes)).symmetric_difference(set(gt_label)))\n",
    "\n",
    "#     if -1 in labels:\n",
    "#         labels.remove(-1)\n",
    "        \n",
    "#     for i,j in enumerate(labels):\n",
    "        \n",
    "#         g1.add_node(len_g1+i,label_gt=j,coord=[-0.0,-0.0,-0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_for_visu(g_updated,g1_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(nx.get_node_attributes(g1_updated,'label_gt').values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_0 = nx.read_gpickle('./noise_100,outliers_20/graphs/graph_0.gpickle')\n",
    "graph_1 = nx.read_gpickle('./noise_100,outliers_20/graphs/graph_1.gpickle')\n",
    "graph_2 = nx.read_gpickle('./noise_100,outliers_20/graphs/graph_2.gpickle')\n",
    "graph_3 = nx.read_gpickle('./noise_100,outliers_20/graphs/graph_3.gpickle')\n",
    "# graph_5 = nx.read_gpickle('./noise_1400,outliers_20/graphs/graph_5.gpickle')\n",
    "\n",
    "grt_01 = np.load('./noise_100,outliers_20/ground_truth.gpickle',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_groundtruth = [grt_01['0,0'], grt_01['0,1'], grt_01['0,2'], grt_01['0,3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graphs = [graph_0,graph_1,graph_2,graph_3]\n",
    "np.save('new_groundtruth.npy',new_groundtruth)\n",
    "nx.write_gpickle(test_graphs,'test_graphs.gpickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graph_0.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_groundtruth[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key,value in new_groundtruth[1].items():\n",
    "    \n",
    "    print(graph_0.nodes[key]['coord'], graph_1.nodes[value]['coord'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_1.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_groundtruth[2].items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_02 = grt_01['02']\n",
    "g0 = graph_0.copy()\n",
    "g2 = graph_2.copy()\n",
    "\n",
    "outliers_label = -1\n",
    "\n",
    "dict_lab = {}\n",
    "for n, node in enumerate(g2.nodes):\n",
    "    if node not in list(gt_02.values()):\n",
    "        dict_lab[node] = {'label_gt':outliers_label}\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        dict_lab[node] = {'label_gt':list(gt_02.keys())[list(gt_02.values()).index(node)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_0.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
