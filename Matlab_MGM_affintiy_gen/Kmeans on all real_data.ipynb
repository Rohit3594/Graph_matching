{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kmeans on spherical coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/home/rohit/PhD_Work/GM_my_version/Graph_matching/\")\n",
    "from sklearn.cluster import KMeans\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from graph_generation.load_graphs_and_create_metadata import dataset_metadata\n",
    "from graph_matching_tools.metrics import matching\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_graph_folder = '/home/rohit/PhD_Work/GM_my_version/Graph_matching/data/Oasis_full_batch_renamed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_permutation_matrix_from_dictionary(matching, g_sizes):\n",
    "    \"\"\"\n",
    "    Create the full permutation matrix from the matching result\n",
    "    :param matching: the matching result for each graph (nodes number, assignment)\n",
    "    :param g_sizes: the list of the size of the different graph\n",
    "    :return: the full permutation matrix\n",
    "    \"\"\"\n",
    "    f_size = int(np.sum(g_sizes))\n",
    "    res = np.zeros((f_size, f_size))\n",
    "\n",
    "    idx1 = 0\n",
    "    for i_g1 in range(len(g_sizes)):\n",
    "        idx2 = 0\n",
    "        for i_g2 in range(len(g_sizes)):\n",
    "            match = matching[\"{},{}\".format(i_g1, i_g2)]\n",
    "            for k in match:\n",
    "                res[idx1 + int(k), idx2 + match[k]] = 1\n",
    "            idx2 += g_sizes[i_g2]\n",
    "        idx1 += g_sizes[i_g1]\n",
    "        \n",
    "    np.fill_diagonal(res,1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_coords(list_graphs):\n",
    "    all_coords = []\n",
    "    for g in list_graphs:\n",
    "        coords = np.array(list(nx.get_node_attributes(g,'sphere_3dcoords').values()))\n",
    "        all_coords.extend(coords)\n",
    "    all_coords = np.array(all_coords)\n",
    "    \n",
    "    return all_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_perm_from_labels(labels):\n",
    "    U = np.zeros((len(labels),len(set(labels))))\n",
    "    \n",
    "    for node,label in zip(range(U.shape[0]),labels):\n",
    "        U[node,label] = 1\n",
    "        \n",
    "    return U @ U.T,U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_from_k_means(k, coords):\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(coords)\n",
    "    \n",
    "    return kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dummy_nodes(graph):\n",
    "\t\tto_remove = []\n",
    "\t\tfor (p, d) in graph.nodes(data=True):\n",
    "\t\t\tif d['is_dummy'] == True:\n",
    "\t\t\t\tto_remove.append(p)\n",
    "\t\tgraph.remove_nodes_from(to_remove)\n",
    "\t\treturn graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_at(arr, output_size, indices):\n",
    "    \n",
    "    # assert len(output_size) == len(indices) == len(arr.shape)\n",
    "    result = np.zeros(output_size)\n",
    "    existing_indices = [np.setdiff1d(np.arange(axis_size), axis_indices,assume_unique=True)\n",
    "                        for axis_size, axis_indices in zip(output_size, indices)]\n",
    "    result[np.ix_(*existing_indices)] = arr\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[86, 88, 83, 87, 94, 91, 94, 83, 94, 88, 92, 89, 92, 94, 89, 85, 91, 89, 83, 96, 101, 87, 89, 91, 83, 82, 89, 82, 87, 86, 93, 89, 89, 81, 91, 89, 91, 92, 91, 86, 87, 83, 93, 92, 89, 89, 91, 81, 88, 90, 89, 96, 89, 94, 90, 93, 90, 89, 86, 91, 89, 89, 85, 85, 84, 88, 94, 86, 81, 83, 81, 84, 87, 83, 91, 86, 96, 91, 86, 78, 82, 79, 95, 95, 86, 80, 85, 85, 80, 96, 89, 94, 87, 91, 86, 83, 85, 97, 83, 86, 91, 90, 85, 81, 89, 92, 95, 91, 88, 92, 83, 88, 95, 84, 84, 87, 80, 93, 86, 88, 77, 92, 92, 94, 94, 97, 101, 86, 86, 79, 87, 93, 85, 89]\n",
      "/n (11832, 11832)\n",
      "/n [101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101]\n",
      "/n (13534, 13534)\n"
     ]
    }
   ],
   "source": [
    "trials = np.sort(os.listdir(path_to_graph_folder))\n",
    "\n",
    "k = 90\n",
    "\n",
    "path_to_graphs = path_to_graph_folder + '/' + '/modified_graphs/'\n",
    "\n",
    "all_files = os.listdir(path_to_graphs)\n",
    "\n",
    "all_graphs = [remove_dummy_nodes(nx.read_gpickle(path_to_graphs+\"/\"+graph)) for graph in all_files]\n",
    "\n",
    "num_nodes = [nx.number_of_nodes(g) for g in all_graphs]\n",
    "print(num_nodes)\n",
    "\n",
    "all_coords = get_all_coords(all_graphs)         \n",
    "\n",
    "kmeans_labels = get_labels_from_k_means(k, all_coords)\n",
    "\n",
    "P,U = create_perm_from_labels(kmeans_labels)\n",
    "\n",
    "kmeans_X = {}\n",
    "kmeans_X['full_assignment_mat'] = P\n",
    "kmeans_X['U'] = U\n",
    "\n",
    "sio.savemat(path_to_graph_folder + '/X_kmeans_real_data.mat',kmeans_X)\n",
    "\n",
    "print('/n',P.shape)\n",
    "\n",
    "\n",
    "# Add dummy rows and columns to the Permutation matrix\n",
    "\n",
    "all_dummy_graphs = [nx.read_gpickle(path_to_graphs+\"/\"+graph) for graph in all_files]\n",
    "sizes_dummy = [nx.number_of_nodes(g) for g in all_dummy_graphs]\n",
    "print('/n',sizes_dummy)\n",
    "\n",
    "\n",
    "dummy_mask = [list(nx.get_node_attributes(graph,'is_dummy').values()) for graph in all_dummy_graphs]\n",
    "dummy_mask = sum(dummy_mask,[])\n",
    "dummy_indexes = [i for i in range(len(dummy_mask)) if dummy_mask[i]==True] \n",
    "\n",
    "\n",
    "X_kmeans_dummy = insert_at(kmeans_X['full_assignment_mat'], (sum(sizes_dummy), sum(sizes_dummy)), (dummy_indexes, dummy_indexes))\n",
    "print('/n',X_kmeans_dummy.shape)\n",
    "\n",
    "X_kmeans_dummy_dict = {}\n",
    "X_kmeans_dummy_dict['full_assignment_mat'] = X_kmeans_dummy\n",
    "\n",
    "sio.savemat(path_to_graph_folder + '/X_kmeans_real_data_dummy.mat',X_kmeans_dummy_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gpickle(prec_scores,'kmeans_prec_score_k_'+ str(k) +'.gpickle')\n",
    "nx.write_gpickle(rec_scores,'kmeans_rec_score_k_'+ str(k) +'.gpickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_70 = nx.read_gpickle('kmeans_score_k_70.gpickle')\n",
    "# k_90 = nx.read_gpickle('kmeans_score_k_90.gpickle')\n",
    "# k_110 = nx.read_gpickle('kmeans_score_k_110.gpickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def score_mean_std(scores):\n",
    "    \n",
    "    avg_scores = []\n",
    "    std_scores = []\n",
    "\n",
    "    for keys,values in scores.items():\n",
    "        avg_scores.append(np.mean(values))\n",
    "        std_scores.append(np.std(values))\n",
    "        \n",
    "    return np.array(avg_scores), np.array(std_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_70_mean, k_70_std  = score_mean_std(k_70)\n",
    "# k_90_mean, k_90_std  = score_mean_std(k_90)\n",
    "# k_110_mean, k_110_std = score_mean_std(k_110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "plt.plot(list(k_70.keys()), k_70_mean ,label = 'k = 70')\n",
    "plt.fill_between(list(k_70.keys()), k_70_mean-k_70_std, k_70_mean + k_70_std, alpha=0.2)\n",
    "\n",
    "\n",
    "plt.plot(list(k_90.keys()), k_90_mean ,label = 'k = 90')\n",
    "plt.fill_between(list(k_90.keys()), k_90_mean - k_90_std, k_90_mean + k_90_std, alpha=0.2)\n",
    "\n",
    "\n",
    "plt.plot(list(k_110.keys()), k_110_mean ,label = 'k = 110')\n",
    "plt.fill_between(list(k_110.keys()), k_110_mean - k_110_std, k_110_mean + k_110_std, alpha=0.2)\n",
    "\n",
    "\n",
    "plt.xlabel('kappa',fontweight=\"bold\")\n",
    "plt.ylabel('F1 score',fontweight=\"bold\")\n",
    "plt.legend(loc = 'lower left')\n",
    "plt.title('kmeans on simultion for different kappa values',fontweight=\"bold\")\n",
    "plt.gca().yaxis.grid(True)\n",
    "plt.gca().invert_xaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
