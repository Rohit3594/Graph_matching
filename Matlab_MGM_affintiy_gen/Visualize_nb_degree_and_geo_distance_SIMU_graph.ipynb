{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle as p\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import networkx as nx\n",
    "import sys\n",
    "import slam.io as sio\n",
    "import networkx as nx\n",
    "import tools.graph_visu as gv\n",
    "import tools.graph_processing as gp\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import trimesh\n",
    "import slam.topology as stop\n",
    "from sphere import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate random color codes for plotting\n",
    "def generate_random_color_codes(num_colors):\n",
    "    \n",
    "    number_of_colors = num_colors\n",
    "    \n",
    "    color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n",
    "             for i in range(number_of_colors)]\n",
    "    \n",
    "    return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dummy_nodes(graph):\n",
    "    G = graph.copy()\n",
    "    to_remove = []\n",
    "    for (p, d) in G.nodes(data=True):\n",
    "        if d['is_dummy'] == True:\n",
    "            to_remove.append(p)\n",
    "    G.remove_nodes_from(to_remove)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simu_path = \"/home/rohit/PhD_Work/GM_my_version/Graph_matching/data/simu_graph/0/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = os.listdir(simu_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_1 = \"/home/rohit/PhD_Work/GM_my_version/Graph_matching/data/simu_graph/simu_test_single_noise/0/noise_700,outliers_varied/graphs/\"\n",
    "real_path = \"/home/rohit/PhD_Work/GM_my_version/Graph_matching/data/Oasis_original_new_renamed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# degree distribution simulated graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degree for simulated graph\n",
    "degree_list = []\n",
    "for graph in os.listdir(path_1):\n",
    "    G = p.load(open(path_1 + graph, \"rb\" )) #read the graphs\n",
    "    #new_G = remove_dummy_nodes(G)\n",
    "    #new_G.remove_edges_from(nx.selfloop_edges(new_G)) # remove self loops\n",
    "    degree_list.append(list(dict(nx.degree(G)).values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_degree = []\n",
    "avg_std = []\n",
    "for degrees in degree_list:\n",
    "    avg_degree.append(np.mean(degrees))\n",
    "    avg_std.append(np.std(degrees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errorfill(x, y, yerr, color=None, alpha_fill=0.2, ax=None,label = None):\n",
    "    ax = ax if ax is not None else plt.gca()\n",
    "    if color is None:\n",
    "        color = next(ax._get_lines.prop_cycler)['color']\n",
    "    if np.isscalar(yerr) or len(yerr) == len(y):\n",
    "        ymin = y - yerr\n",
    "        ymax = y + yerr\n",
    "    elif len(yerr) == 2:\n",
    "        ymin, ymax = yerr\n",
    "    ax.plot(x, y, color=color,label= label)\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.fill_between(x, ymax, ymin, color=color, alpha=alpha_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degree for Real graph\n",
    "degree_list_real = []\n",
    "for graph in os.listdir(real_path):\n",
    "    G = p.load(open(real_path + graph, \"rb\" )) #read the graphs\n",
    "    new_G = remove_dummy_nodes(G)\n",
    "    new_G.remove_edges_from(nx.selfloop_edges(new_G)) # remove self loops\n",
    "    degree_list_real.append(list(dict(nx.degree(new_G)).values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_degree_real = []\n",
    "avg_std_real = []\n",
    "for degrees in degree_list_real:\n",
    "    avg_degree_real.append(np.mean(degrees))\n",
    "    avg_std_real.append(np.std(degrees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,8))\n",
    "\n",
    "errorfill(np.arange(0,len(avg_degree)),np.array(avg_degree), np.array(avg_std),label=\"simu\")\n",
    "errorfill(np.arange(0,len(avg_degree_real)),np.array(avg_degree_real), np.array(avg_std_real),label='real')\n",
    "\n",
    "plt.title(\"Degree, simulated Graphs Noise 1000,Outliers 16\")\n",
    "plt.xlabel('# graphs')\n",
    "plt.ylabel('Degree')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "color = generate_random_color_codes(len(degree_list)+len(degree_list_real))\n",
    "\n",
    "real_graph_names = [\"R_\"+names for names in os.listdir(real_path)]\n",
    "\n",
    "\n",
    "fig = ff.create_distplot(degree_list + degree_list_real, os.listdir(path_1)+real_graph_names, show_hist=False, colors=color)\n",
    "#fig = ff.create_distplot([avg_degree_list, avg_degree_list_real], [\"avg_degree_simu\",\"avg_degree_real\"], show_hist=False, colors=color)\n",
    "\n",
    "# Add title\n",
    "fig.update_layout(title_text='Degree density simu 1000 noise 0 outliers and Real data')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# average neighbour degree distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree_of_neighb(G):\n",
    "    nb_degree_dict = {}\n",
    "    for node in G:\n",
    "        nb_degree = []\n",
    "        for nb in G.neighbors(node):\n",
    "            nb_degree.append(G.degree(nb))\n",
    "        nb_degree_dict[node] = nb_degree\n",
    "    return nb_degree_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_graph_nb_degree = []\n",
    "for graph in os.listdir(path_1):\n",
    "    graph = nx.read_gpickle(path_1+graph)\n",
    "    #graph = remove_dummy_nodes(graph)\n",
    "    #graph.remove_edges_from(nx.selfloop_edges(graph)) # remove self loops\n",
    "    all_graph_nb_degree.append(degree_of_neighb(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_nb_degree_all_graph = []\n",
    "for degree_dict in all_graph_nb_degree:\n",
    "    avg_degree = [np.mean(lst) for lst in list(degree_dict.values())]\n",
    "    avg_nb_degree_all_graph.append(avg_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = generate_random_color_codes(len(avg_nb_degree_all_graph))\n",
    "fig = ff.create_distplot(avg_nb_degree_all_graph, os.listdir(path_1), show_hist=False,bin_size=.2, colors=color)\n",
    "\n",
    "# Add title\n",
    "fig.update_layout(title_text='Average neigbour degree for simu graphs 900 noise 0 outliers')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Neighbour Geo distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neighbours geo distance\n",
    "\n",
    "def geo_dist_of_neighb(G):\n",
    "    nb_dist_dict = {}\n",
    "    for node in G:\n",
    "        nb_geo_dist = []\n",
    "        for nb in G.neighbors(node):\n",
    "            nb_geo_dist.append(G.get_edge_data(node,nb)['geodesic_distance'])\n",
    "        nb_dist_dict[node] = nb_geo_dist\n",
    "    return nb_dist_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_graph_nb_distance = []\n",
    "for graph in os.listdir(path_1):\n",
    "    graph = nx.read_gpickle(path_1+graph)\n",
    "    #graph = remove_dummy_nodes(graph)\n",
    "    #graph.remove_edges_from(nx.selfloop_edges(graph)) # remove self loops\n",
    "    all_graph_nb_distance.append(geo_dist_of_neighb(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_nb_dist_all_graph = []\n",
    "for dist_dict in all_graph_nb_distance:\n",
    "    avg_dist = [np.mean(lst) for lst in list(dist_dict.values())]\n",
    "    avg_nb_dist_all_graph.append(avg_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = generate_random_color_codes(len(avg_nb_dist_all_graph))\n",
    "fig = ff.create_distplot(avg_nb_dist_all_graph, os.listdir(path_1), show_hist=False,bin_size=.2, colors=color)\n",
    "\n",
    "# Add title\n",
    "fig.update_layout(title_text='Average neigbour geo distance for simu graphs 900 noise 0 outliers')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average geo distance Real and Simu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_path = \"/home/rohit/PhD_Work/GM_my_version/Graph_matching/data/OASIS_full_batch/modified_graphs/\"\n",
    "path_1 = \"/home/rohit/PhD_Work/GM_my_version/Graph_matching/data/simu_graph/0/noise_1000,outliers_0/graphs/\"\n",
    "simu_path = \"/home/rohit/PhD_Work/GM_my_version/Graph_matching/data/simu_graph/0/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_edge_len(G):\n",
    "    \n",
    "    all_geo = [z['geodesic_distance'] for x,y,z in list(G.edges.data())]\n",
    "    mean_geo = np.array(all_geo).mean()\n",
    "    std = np.std(all_geo)\n",
    "    \n",
    "    return mean_geo,std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simu_graph_geo_distance = []\n",
    "simu_graph_std = []\n",
    "for folder in folder_name:\n",
    "    if os.path.isdir(simu_path+folder):\n",
    "        print(folder)\n",
    "    \n",
    "        mean_graph_geo_distance = []\n",
    "        mean_graph_std = []\n",
    "        \n",
    "        graph_path = simu_path+folder+'/'+'graphs/'\n",
    "        \n",
    "        for graph in os.listdir(graph_path):\n",
    "            graph = nx.read_gpickle(graph_path+graph)\n",
    "            #graph = remove_dummy_nodes(graph)\n",
    "            #graph.remove_edges_from(nx.selfloop_edges(graph)) # remove self loops\n",
    "            \n",
    "            mean_geo,mean_std = mean_edge_len(graph)\n",
    "            \n",
    "            mean_graph_geo_distance.append(mean_geo)\n",
    "            mean_graph_std.append(mean_std)\n",
    "        \n",
    "        simu_graph_geo_distance.append(mean_graph_geo_distance)\n",
    "        simu_graph_std.append(mean_graph_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_graph_geo_distance = []\n",
    "real_graph_std = []\n",
    "for graph in os.listdir(real_path):\n",
    "    graph = nx.read_gpickle(real_path+graph)\n",
    "    graph = remove_dummy_nodes(graph)\n",
    "    graph.remove_edges_from(nx.selfloop_edges(graph)) # remove self loops\n",
    "    \n",
    "    mean_geo,mean_std = mean_edge_len(graph)\n",
    "    \n",
    "    real_graph_geo_distance.append(mean_geo)\n",
    "    real_graph_std.append(mean_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,8))\n",
    "\n",
    "errorfill(np.arange(0,len(simu_graph_geo_distance[4])),np.array(simu_graph_geo_distance[4]), np.array(simu_graph_std[4]),label=\"simu\")\n",
    "errorfill(np.arange(0,len(real_graph_geo_distance)),np.array(real_graph_geo_distance), np.array(real_graph_std),label='real')\n",
    "\n",
    "plt.title(\"Geodesic distance, simulated Graphs Noise 1000,Outliers 0\")\n",
    "plt.xlabel('# graphs')\n",
    "plt.ylabel('Geodesic distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#color = generate_random_color_codes(len(real_graph_geo_distance)+len(simu_graph_geo_distance))\n",
    "simu_graph_names = [name for name in os.listdir(simu_path) if os.path.isdir(simu_path+name)]\n",
    "\n",
    "color = generate_random_color_codes(len(simu_graph_names)+1)\n",
    "\n",
    "#real_graph_names = [\"R_\"+names for names in os.listdir(real_path)]\n",
    "\n",
    "fig = ff.create_distplot([real_graph_geo_distance]+simu_graph_geo_distance,[\"real_graph\"] + simu_graph_names\n",
    "                         , show_hist=False,bin_size=.2, colors=color)\n",
    "\n",
    "# Add title\n",
    "fig.update_layout(title_text='Average Geo distance for simu graphs and real graphs')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.random.normal(0, 0.8, 1000)\n",
    "x2 = np.random.normal(-2, 1, 1000)\n",
    "x3 = np.random.normal(3, 2, 1000)\n",
    "\n",
    "kwargs = dict(histtype='stepfilled', alpha=0.5, bins=40)\n",
    "\n",
    "plt.hist(x1, **kwargs)\n",
    "plt.hist(x2, **kwargs)\n",
    "plt.hist(x3, **kwargs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_permutation = np.random.permutation(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for original_node, current_node in enumerate(ground_truth_permutation):\n",
    "    print(original_node,current_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(np.array([2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.multivariate_normal(np.zeros(3), np.eye(3) * 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_coordinate = np.array([-0.3911855 ,  4.85146353, -1.01699333])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_coordinate / np.linalg.norm(noisy_coordinate) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sphere_random_sampling(vertex_number=100, radius=1.0):\n",
    "    \"\"\"\n",
    "    generate a sphere with random sampling\n",
    "    :param vertex_number: number of vertices in the output spherical mesh\n",
    "    :param radius: radius of the output sphere\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    coords = np.zeros((vertex_number, 3))\n",
    "    for i in range(vertex_number):\n",
    "        M = np.random.normal(size=(3, 3))\n",
    "        Q, R = np.linalg.qr(M)\n",
    "        coords[i, :] = Q[:, 0].transpose() * np.sign(R[0, 0])\n",
    "    if radius != 1:\n",
    "        coords = radius * coords\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tri_from_hull(vertices):\n",
    "    \"\"\"\n",
    "    compute faces from vertices using trimesh convex hull\n",
    "    :param vertices: (n, 3) float\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    mesh = trimesh.Trimesh(vertices=vertices, process=False)\n",
    "    return mesh.convex_hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sphere_random_sampling = generate_sphere_random_sampling(vertex_number=4, radius=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_f = tri_from_hull(sphere_random_sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sphere_random_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.nodes[0]['coord']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_demo = tri_from_hull(list(nx.get_node_attributes(graph,'coord').values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adja = stop.edges_to_adjacency_matrix(edges_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = [tuple((u,v)) for u,v in zip(adja.nonzero()[0],adja.nonzero()[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adja.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_a, coordinate_b = noisy_graph.nodes[edge[0]][\"coord\"], noisy_graph.nodes[edge[1]][\"coord\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noisy_graph_2(original_graph, nb_vertices, sigma_noise_nodes=1, sigma_noise_edges=1, radius=100):\n",
    "    # Perturbate the coordinates\n",
    "    # noisy_coord = [points+np.random.multivariate_normal(np.zeros(3), np.eye(3) * sigma_noise_nodes)\n",
    "    # \tfor points in list(nx.get_node_attributes(original_graph,'coord').values())]\n",
    "\n",
    "    ground_truth_permutation = np.arange(nb_vertices)\n",
    "    # create a new graph\n",
    "    noisy_graph = nx.Graph()\n",
    "    # add the nodes (not very clean but it works fine and run in no time)\n",
    "    for node_to_add in range(len(ground_truth_permutation)):\n",
    "        for original_node, current_node in enumerate(ground_truth_permutation):\n",
    "            if current_node == node_to_add:\n",
    "                # noisy_coordinate = original_graph.nodes[original_node][\"coord\"] + \\\n",
    "                # \tnp.random.multivariate_normal(np.zeros(3), np.eye(3) * sigma_noise_nodes)\n",
    "\n",
    "                # Sampling from Von Mises - Fisher distribution\n",
    "                original_coord = original_graph.nodes[original_node][\"coord\"]\n",
    "                mean_original = original_coord / np.linalg.norm(original_coord)  # convert to mean vector\n",
    "                noisy_coordinate = Sphere().sample(1, distribution='vMF', mu=mean_original,\n",
    "                                                   kappa=sigma_noise_nodes).sample[0]\n",
    "\n",
    "                #noisy_coordinate = noisy_coordinate / np.linalg.norm(noisy_coordinate) * radius\n",
    "                noisy_coordinate  = noisy_coordinate * np.linalg.norm(original_coord)\n",
    "                noisy_graph.add_node(node_to_add, coord=noisy_coordinate)\n",
    "\n",
    "    return noisy_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noisy_graph(original_graph, nb_vertices, sigma_noise_nodes = 1, sigma_noise_edges = 1, radius = 100):\n",
    "    \n",
    "    # generate ground_truth permutation\n",
    "    #ground_truth_permutation = np.random.permutation(nb_vertices)\n",
    "    ground_truth_permutation = np.arange(nb_vertices)\n",
    "    \n",
    "    # create a new graph\n",
    "    noisy_graph = nx.Graph()\n",
    "\n",
    "    # add the nodes (not very clean but it works fine and run in no time)\n",
    "    for node_to_add in range(len(ground_truth_permutation)):\n",
    "        for original_node, current_node in enumerate(ground_truth_permutation):\n",
    "            if current_node == node_to_add:\n",
    "                noisy_coordinate = original_graph.nodes[original_node][\"coord\"] + \\\n",
    "                    np.random.multivariate_normal(np.zeros(3), np.eye(3) * sigma_noise_nodes)\n",
    "\n",
    "                # We project on the sphere\n",
    "                noisy_coordinate = noisy_coordinate / np.linalg.norm(noisy_coordinate) * radius\n",
    "                noisy_graph.add_node(node_to_add, coord = noisy_coordinate)\n",
    "\n",
    "    # add the necessary nodes\n",
    "    # for original_node, corresponding_node in enumerate(ground_truth_permutation):\n",
    "    #     noisy_coordinate = original_graph.nodes[original_node][\"coord\"] + \\\n",
    "    #                        np.random.multivariate_normal(np.zeros(3), np.eye(3) * sigma_noise_nodes)\n",
    "    #     # On projete ce point sur la sphère\n",
    "    #     noisy_coordinate = noisy_coordinate / np.linalg.norm(noisy_coordinate) * radius\n",
    "    #     noisy_graph.add_node(corresponding_node, coord = noisy_coordinate)\n",
    "        \n",
    "    compute_noisy_edges = tri_from_hull(list(nx.get_node_attributes(noisy_graph,'coord').values())) # take all peturbated coord and comp conv hull.\n",
    "    adja = stop.edges_to_adjacency_matrix(compute_noisy_edges) # compute the new adjacency mat\n",
    "    edge_list = [tuple((u,v)) for u,v in zip(adja.nonzero()[0],adja.nonzero()[1])] # convert to edge list to add edge attributes.\n",
    "\n",
    "\n",
    "    # add the edges\n",
    "    for edge in edge_list:\n",
    "\n",
    "        # get the original and corresponding ends\n",
    "        #end_a_corresponding, end_b_corresponding = ground_truth_permutation[edge[0]], ground_truth_permutation[edge[1]]\n",
    "        coordinate_a, coordinate_b = noisy_graph.nodes[edge[0]][\"coord\"], noisy_graph.nodes[edge[1]][\"coord\"]\n",
    "\n",
    "        # calculate noisy geodesic distance\n",
    "        noisy_geodesic_dist = gp.compute_geodesic_distance_sphere(coordinate_a, coordinate_b, radius)\n",
    "\n",
    "        # Add the new edge to the graph\n",
    "        noisy_graph.add_edge(edge[0],edge[1], weight = 1.0, geodesic_distance = noisy_geodesic_dist)\n",
    "    \n",
    "    return ground_truth_permutation, noisy_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gpickle(\"/home/rohit/PhD_Work/GM_my_version/Graph_matching/data/simu_graph/0/\"+\"reference_500-900.gpickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_coord =  list(nx.get_node_attributes(G,'coord').values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_permutation, noisy_graph = generate_noisy_graph(G,20,50,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_graph_2 = generate_noisy_graph_2(G,20,100,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normal_coord = list(nx.get_node_attributes(G,'coord').values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(sphere_random_sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "original_coord + list(sphere_random_sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_coords = list(nx.get_node_attributes(G,'coord').values())\n",
    "# mean_original = original_coord / np.linalg.norm(original_coord) * 100\n",
    "\n",
    "# perturbed_coordinate = [list(Sphere().sample(1, distribution='vMF', mu=mean_original[i],\n",
    "#                                                    kappa=200).sample[0]) for i in range(len(mean_original))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_noisy_edges = tri_from_hull(np.array(list(nx.get_node_attributes(noisy_graph_2,'coord').values()))) # take all peturbated coord and comp conv hull.\n",
    "adja = stop.edges_to_adjacency_matrix(compute_noisy_edges) # compute the new adjacency mat\n",
    "edge_list = [tuple((u,v)) for u,v in zip(adja.nonzero()[0],adja.nonzero()[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute_noisy_edges = tri_from_hull(np.array(perturbed_coordinate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(compute_noisy_edges.vertices.view(np.ndarray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_coords[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_noisy_edges.vertices.view(np.ndarray)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(nx.get_node_attributes(noisy_graph,'coord').values())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(nx.get_node_attributes(noisy_graph_2,'coord').values())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(nx.get_node_attributes(G,'coord').values())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = list(nx.get_node_attributes(noisy_graph_2,'coord').values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hull = spatial.ConvexHull(coords,\n",
    "                              qhull_options='QbB Pp Qx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hull.vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = np.sort(hull.vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices = hull.points[vid].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros(len(hull.points), dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hull.simplices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = generate_sphere_random_sampling(5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(compute_noisy_edges.vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(edge_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(nx.get_node_attributes(noisy_graph_2,'coord').values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aj = gph.edges_to_coo(hh.edges,data=np.ones(len(hh.edges),dtype=np.int8))\n",
    "aj = stop.edges_to_adjacency_matrix(hh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_list = [tuple((u,v)) for u,v in zip(aj.nonzero()[0],aj.nonzero()[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coordinate_a, coordinate_b = noisy_graph.nodes[edge_list[2][0]][\"coord\"], noisy_graph.nodes[edge_list[2][1]][\"coord\"]\n",
    "# noisy_geodesic_dist = gp.compute_geodesic_distance_sphere(coordinate_a, coordinate_b, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grph_noise = nx.from_numpy_matrix(aj.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_coord[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(nx.get_node_attributes(G,'coord').values())[:4]\n",
    "#normal_coord = list(nx.get_node_attributes(G,'coord').values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hh.vertices.view(np.ndarray)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_perm = []\n",
    "for ar1 in hh.vertices.view(np.ndarray):\n",
    "    index = 0\n",
    "    for ar2 in noisy_coord:\n",
    "        if np.mean(ar1) == np.mean(ar2):\n",
    "            gt_perm.append(index)\n",
    "            index+=1\n",
    "            break\n",
    "        else:\n",
    "            index+=1\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh.vertices[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_coord[gt_perm[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cord = [points+np.random.multivariate_normal(np.zeros(3), np.eye(3) * 0) \n",
    "        for points in list(nx.get_node_attributes(G,'coord').values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_hull = tri_from_hull(list(nx.get_node_attributes(ng,'coord').values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_coord = np.load('noisy coord.npy')\n",
    "conv_hul_coord = np.load('convex hull vertices.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_coord[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(nx.get_node_attributes(G,'coord').values())[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_hul_coord[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = []\n",
    "sorted_coord = []\n",
    "missing_coord = []\n",
    "for ar1 in conv_hul_coord:\n",
    "    for index in range(len(noise_coord)):\n",
    "        if np.mean(ar1) == np.mean(noise_coord[index]):\n",
    "            perm.append(index)\n",
    "            sorted_coord.append(noise_coord[index])\n",
    "            \n",
    "    missing_coord.append(ar1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "from chull import Vector,Hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sphere=[]  \n",
    "for i in range(20):\n",
    "    x,y,z = 2*random()-1,2*random()-1,2*random()-1\n",
    "    if x*x+y*y+z*z < 1.0:\n",
    "        sphere.append(Vector(x,y,z))  \n",
    "h=Hull(sphere)  \n",
    "h.Print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_graphs = './data/Oasis_original_new_with_dummy/modified_graphs/'\n",
    "list_graphs = [nx.read_gpickle(path_to_graphs+'/'+graph) for graph in np.sort(os.listdir(path_to_graphs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vertex_index': 1357,\n",
       " 'sphere_3dcoords': array([  6.50138903, -93.98175049, -33.54344177]),\n",
       " 'sphere_coords': [-1.5017292499542236, 1.9128626585006714],\n",
       " 'basin_label': 307.0,\n",
       " 'basin_area': 447.01047,\n",
       " 'depth': -0.18439683,\n",
       " 'basin_thickness': 2.5869646072387695,\n",
       " 'ico100_7_vertex_index': 7574,\n",
       " 'label_neuroimage': 28,\n",
       " 'label_media': 90,\n",
       " 'sphere_3dcoords_noreg': array([ 17.402021, -91.770744, -35.71135 ], dtype=float32),\n",
       " 'ico100_7_vertex_index_noreg': 11492,\n",
       " 'is_dummy': False}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_graphs[0].nodes.data()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
