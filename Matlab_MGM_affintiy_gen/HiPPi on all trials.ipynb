{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/home/rohit/PhD_Work/GM_my_version/Graph_matching/\")\n",
    "from sklearn.cluster import KMeans\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from graph_matching_tools.io.graph_dataset import GraphDataset\n",
    "from graph_matching_tools.metrics import matching\n",
    "import matplotlib.pyplot as plt\n",
    "from graph_matching_tools.algorithms.multiway.hippi import hippi_multiway_matching\n",
    "from graph_matching_tools.algorithms.kernels.gaussian import create_gaussian_node_kernel\n",
    "from graph_matching_tools.algorithms.kernels.utils import create_full_node_affinity_matrix\n",
    "from graph_matching_tools.algorithms.multiway.stiefel import sparse_stiefel_manifold_sync\n",
    "\n",
    "import scipy.io as sio\n",
    "# from KerGM_python.grackel import *\n",
    "sys.path.append(\"/home/rohit/PhD_Work/GM_my_version/Graph_matching/KerGM_python/grackel/\")\n",
    "import re\n",
    "import KerGM_python.grackel.grackelpy.algorithms.matching as match\n",
    "import KerGM_python.grackel.grackelpy.algorithms.multimatch as mm\n",
    "import KerGM_python.grackel.grackelpy.algorithms.quickmatch as qm\n",
    "import KerGM_python.grackel.grackelpy.utils.measures as measures\n",
    "import KerGM_python.grackel.grackelpy.utils.kernels as kern\n",
    "import KerGM_python.grackel.grackelpy.utils.utils as utils\n",
    "import KerGM_python.grackel.graph_processing.graph_processing as gp\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_permutation_matrix_from_dictionary(matching, g_sizes):\n",
    "    \"\"\"\n",
    "    Create the full permutation matrix from the matching result\n",
    "    :param matching: the matching result for each graph (nodes number, assignment)\n",
    "    :param g_sizes: the list of the size of the different graph\n",
    "    :return: the full permutation matrix\n",
    "    \"\"\"\n",
    "    f_size = int(np.sum(g_sizes))\n",
    "    res = np.zeros((f_size, f_size))\n",
    "\n",
    "    idx1 = 0\n",
    "    for i_g1 in range(len(g_sizes)):\n",
    "        idx2 = 0\n",
    "        for i_g2 in range(len(g_sizes)):\n",
    "            match = matching[\"{},{}\".format(i_g1, i_g2)]\n",
    "            for k in match:\n",
    "                res[idx1 + int(k), idx2 + match[k]] = 1\n",
    "            idx2 += g_sizes[i_g2]\n",
    "        idx1 += g_sizes[i_g1]\n",
    "        \n",
    "    np.fill_diagonal(res,1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_full_adjacency_matrix(graphs):\n",
    "    \"\"\"\n",
    "    Create the full adjacency matrix with the matrices on the diagonal\n",
    "\n",
    "    :param list graphs: the list of graphs\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    sizes = []\n",
    "    full_size = 0\n",
    "    for g in graphs:\n",
    "        size = nx.number_of_nodes(g)\n",
    "        sizes.append(size)\n",
    "        full_size += size\n",
    "\n",
    "    a = np.zeros((full_size, full_size))\n",
    "\n",
    "    index = 0\n",
    "    for i in range(len(graphs)):\n",
    "        adj = (nx.adjacency_matrix(graphs[i])).toarray()\n",
    "        a[index:index+sizes[i], index:index+sizes[i]] = adj\n",
    "        index += sizes[i]\n",
    "\n",
    "    return a, sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_graph_folder = '/home/rohit/PhD_Work/GM_my_version/Graph_matching/data/simu_graph/simu_test_single_noise/'\n",
    "path_to_dummy_graphs_folder = '/home/rohit/PhD_Work/GM_my_version/Graph_matching/data/simu_graph/test_with_dummy/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:  0.0\n",
      "Noise folder:  noise_100,outliers_varied\n",
      "Noise folder:  noise_400,outliers_varied\n",
      "Noise folder:  noise_700,outliers_varied\n",
      "Noise folder:  noise_1300,outliers_varied\n",
      "Noise folder:  noise_1000,outliers_varied\n",
      "trial:  0.1\n",
      "Noise folder:  noise_100,outliers_varied\n",
      "Noise folder:  noise_400,outliers_varied\n",
      "Noise folder:  noise_700,outliers_varied\n",
      "Noise folder:  noise_1300,outliers_varied\n",
      "Noise folder:  noise_1000,outliers_varied\n",
      "trial:  0.2\n",
      "Noise folder:  noise_100,outliers_varied\n",
      "P shape (11427, 11427)\n",
      "s shape (11427, 11427)\n",
      "Noise folder:  noise_400,outliers_varied\n",
      "P shape (11323, 11323)\n",
      "s shape (11323, 11323)\n",
      "Noise folder:  noise_700,outliers_varied\n",
      "P shape (11333, 11333)\n",
      "s shape (11333, 11333)\n",
      "Noise folder:  noise_1300,outliers_varied\n",
      "P shape (11292, 11292)\n",
      "s shape (11292, 11292)\n",
      "Noise folder:  noise_1000,outliers_varied\n",
      "P shape (11262, 11262)\n",
      "s shape (11262, 11262)\n",
      "trial:  0.3\n",
      "Noise folder:  noise_100,outliers_varied\n",
      "P shape (11350, 11350)\n",
      "s shape (11350, 11350)\n",
      "Noise folder:  noise_400,outliers_varied\n",
      "P shape (11344, 11344)\n",
      "s shape (11344, 11344)\n",
      "Noise folder:  noise_700,outliers_varied\n",
      "P shape (11218, 11218)\n",
      "s shape (11218, 11218)\n",
      "Noise folder:  noise_1300,outliers_varied\n",
      "P shape (11229, 11229)\n",
      "s shape (11229, 11229)\n",
      "Noise folder:  noise_1000,outliers_varied\n",
      "P shape (11363, 11363)\n",
      "s shape (11363, 11363)\n"
     ]
    }
   ],
   "source": [
    "trials = np.sort(os.listdir(path_to_graph_folder))\n",
    "\n",
    "sigma = 200\n",
    "u_dim = 100 # dim for universe of nodes\n",
    "\n",
    "scores = {100:[],400:[],700:[],1000:[],1300:[]}\n",
    "prec_scores = {100:[],400:[],700:[],1000:[],1300:[]}\n",
    "rec_scores = {100:[],400:[],700:[],1000:[],1300:[]}\n",
    "\n",
    "for trial in trials:\n",
    "    \n",
    "    if float(trial) <= 0.3:\n",
    "        \n",
    "        print('trial: ', trial)\n",
    "\n",
    "        all_files = os.listdir(path_to_graph_folder+trial)\n",
    "\n",
    "        for folder in all_files:\n",
    "\n",
    "            if os.path.isdir(path_to_graph_folder+trial+'/'+ folder):\n",
    "\n",
    "                print('Noise folder: ',folder)\n",
    "                \n",
    "#                 path_to_dummy_graphs = path_to_dummy_graphs_folder + '/' + trial + '/' + folder+'/0/graphs/'\n",
    "                path_to_graphs = path_to_graph_folder + '/' + trial + '/' + folder+'/graphs/'\n",
    "                path_to_groundtruth_ref = path_to_graph_folder + '/' + trial +'/' + folder + '/permutation_to_ref_graph.gpickle'\n",
    "                path_to_groundtruth  = path_to_graph_folder + '/' + trial + '/' + folder + '/ground_truth.gpickle'\n",
    "            \n",
    "        \n",
    "                noise = folder.split(',')[0].split('_')[1]\n",
    "                \n",
    "                if exists(path_to_graph_folder + '/' + trial + '/' + folder +'/X_HiPPi.mat'):   \n",
    "                    continue\n",
    "            \n",
    "            \n",
    "                graph_meta = GraphDataset(path_to_graphs, path_to_groundtruth_ref)\n",
    "                ground_truth =  nx.read_gpickle(path_to_groundtruth)\n",
    "    \n",
    "#                 graphs = [nx.read_gpickle(path_to_dummy_graphs + graph) for graph in np.sort(os.listdir(path_to_dummy_graphs))]\n",
    "#                 sizes = [nx.number_of_nodes(graph) for graph in graphs]\n",
    "        \n",
    "                res = get_permutation_matrix_from_dictionary(ground_truth, graph_meta.sizes)\n",
    "                \n",
    "                node_kernel = create_gaussian_node_kernel(sigma,'coord')\n",
    "                knode = create_full_node_affinity_matrix(graph_meta.list_graphs, node_kernel)\n",
    "                \n",
    "                s = np.eye(knode.shape[0], knode.shape[1])\n",
    "#                 path_init = path_to_graph_folder + '/'+ trial + '/' + folder + '/X_kmeans.mat'                \n",
    "#                 X_kmeans = sio.loadmat(path_init)\n",
    "                #u = X_kmeans['U']\n",
    "#                 x = X_kmeans['full_assignment_mat']\n",
    "                \n",
    "\n",
    "                # Old Implementation\n",
    "#                 node_kernel = kern.create_node_kernel(sigma, \"coord\")   #Change coord to sphere_3dcoords for real data\n",
    "#                 knode = mm.create_full_node_affinity_matrix(graph_meta.list_graphs, node_kernel)\n",
    "#                 s, _ = utils.create_full_adjacency_matrix(graph_meta.list_graphs)\n",
    "#                 s = np.eye(knode.shape[0], knode.shape[1])\n",
    "#                 u = mm.hippi_multiway_matching(s, graph_meta.sizes, knode, u_dim)\n",
    "#                 P = u @ u.T\n",
    "\n",
    "#                 rng = np.random.default_rng()\n",
    "#                 u = rng.uniform(size=(s.shape[0], u_dim))\n",
    "\n",
    "\n",
    "                #u = sparse_stiefel_manifold_sync(x, u_dim, graph_meta.sizes)\n",
    "                #print('u shape', u.shape)\n",
    "        \n",
    "                U = hippi_multiway_matching(s, graph_meta.sizes, knode, u_dim)\n",
    "\n",
    "                P = U @ U.T\n",
    "\n",
    "                HiPPi_X = {}\n",
    "                HiPPi_X['full_assignment_mat'] = P\n",
    "                \n",
    "                print('P shape', P.shape)\n",
    "                print('s shape', s.shape)\n",
    "\n",
    "                sio.savemat(path_to_graph_folder + '/' + trial + '/' + folder + '/X_HiPPi.mat',HiPPi_X)\n",
    "\n",
    "                f1, prec, rec = matching.compute_f1score(P,res)\n",
    "\n",
    "                scores[int(noise)].append(f1)\n",
    "                prec_scores[int(noise)].append(prec)\n",
    "                rec_scores[int(noise)].append(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
