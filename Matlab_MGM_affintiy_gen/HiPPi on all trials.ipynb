{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/home/rohit/PhD_Work/GM_my_version/Graph_matching/\")\n",
    "from sklearn.cluster import KMeans\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from graph_matching_tools.io.graph_dataset import GraphDataset\n",
    "from graph_matching_tools.metrics import matching\n",
    "import matplotlib.pyplot as plt\n",
    "from graph_matching_tools.algorithms.multiway.hippi import hippi_multiway_matching\n",
    "from graph_matching_tools.algorithms.kernels.gaussian import create_gaussian_node_kernel\n",
    "from graph_matching_tools.algorithms.kernels.utils import create_full_node_affinity_matrix\n",
    "import scipy.io as sio\n",
    "# from KerGM_python.grackel import *\n",
    "sys.path.append(\"/home/rohit/PhD_Work/GM_my_version/Graph_matching/KerGM_python/grackel/\")\n",
    "import re\n",
    "import KerGM_python.grackel.grackelpy.algorithms.matching as match\n",
    "import KerGM_python.grackel.grackelpy.algorithms.multimatch as mm\n",
    "import KerGM_python.grackel.grackelpy.algorithms.quickmatch as qm\n",
    "import KerGM_python.grackel.grackelpy.utils.measures as measures\n",
    "import KerGM_python.grackel.grackelpy.utils.kernels as kern\n",
    "import KerGM_python.grackel.grackelpy.utils.utils as utils\n",
    "import KerGM_python.grackel.graph_processing.graph_processing as gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_permutation_matrix_from_dictionary(matching, g_sizes):\n",
    "    \"\"\"\n",
    "    Create the full permutation matrix from the matching result\n",
    "    :param matching: the matching result for each graph (nodes number, assignment)\n",
    "    :param g_sizes: the list of the size of the different graph\n",
    "    :return: the full permutation matrix\n",
    "    \"\"\"\n",
    "    f_size = int(np.sum(g_sizes))\n",
    "    res = np.zeros((f_size, f_size))\n",
    "\n",
    "    idx1 = 0\n",
    "    for i_g1 in range(len(g_sizes)):\n",
    "        idx2 = 0\n",
    "        for i_g2 in range(len(g_sizes)):\n",
    "            match = matching[\"{},{}\".format(i_g1, i_g2)]\n",
    "            for k in match:\n",
    "                res[idx1 + int(k), idx2 + match[k]] = 1\n",
    "            idx2 += g_sizes[i_g2]\n",
    "        idx1 += g_sizes[i_g1]\n",
    "        \n",
    "    np.fill_diagonal(res,1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_full_adjacency_matrix(graphs):\n",
    "    \"\"\"\n",
    "    Create the full adjacency matrix with the matrices on the diagonal\n",
    "\n",
    "    :param list graphs: the list of graphs\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    sizes = []\n",
    "    full_size = 0\n",
    "    for g in graphs:\n",
    "        size = nx.number_of_nodes(g)\n",
    "        sizes.append(size)\n",
    "        full_size += size\n",
    "\n",
    "    a = np.zeros((full_size, full_size))\n",
    "\n",
    "    index = 0\n",
    "    for i in range(len(graphs)):\n",
    "        adj = (nx.adjacency_matrix(graphs[i])).toarray()\n",
    "        a[index:index+sizes[i], index:index+sizes[i]] = adj\n",
    "        index += sizes[i]\n",
    "\n",
    "    return a, sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_graph_folder = '/home/rohit/PhD_Work/GM_my_version/Graph_matching/data/simu_graph/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:  0\n",
      "Noise folder:  noise_100,outliers_varied\n",
      "P shape (371, 371)\n",
      "s shape (371, 371)\n",
      "Noise folder:  noise_400,outliers_varied\n",
      "P shape (386, 386)\n",
      "s shape (386, 386)\n",
      "Noise folder:  noise_700,outliers_varied\n",
      "P shape (331, 331)\n",
      "s shape (331, 331)\n",
      "Noise folder:  noise_1300,outliers_varied\n",
      "P shape (371, 371)\n",
      "s shape (371, 371)\n",
      "Noise folder:  noise_1000,outliers_varied\n",
      "P shape (391, 391)\n",
      "s shape (391, 391)\n",
      "trial:  1\n",
      "Noise folder:  noise_100,outliers_varied\n",
      "P shape (399, 399)\n",
      "s shape (399, 399)\n",
      "Noise folder:  noise_400,outliers_varied\n",
      "P shape (376, 376)\n",
      "s shape (376, 376)\n",
      "Noise folder:  noise_700,outliers_varied\n",
      "P shape (373, 373)\n",
      "s shape (373, 373)\n",
      "Noise folder:  noise_1300,outliers_varied\n",
      "P shape (346, 346)\n",
      "s shape (346, 346)\n",
      "Noise folder:  noise_1000,outliers_varied\n",
      "P shape (356, 356)\n",
      "s shape (356, 356)\n",
      "trial:  2\n",
      "Noise folder:  noise_100,outliers_varied\n",
      "P shape (374, 374)\n",
      "s shape (374, 374)\n",
      "Noise folder:  noise_400,outliers_varied\n",
      "P shape (406, 406)\n",
      "s shape (406, 406)\n",
      "Noise folder:  noise_700,outliers_varied\n",
      "P shape (401, 401)\n",
      "s shape (401, 401)\n",
      "Noise folder:  noise_1300,outliers_varied\n",
      "P shape (378, 378)\n",
      "s shape (378, 378)\n",
      "Noise folder:  noise_1000,outliers_varied\n",
      "P shape (379, 379)\n",
      "s shape (379, 379)\n",
      "trial:  3\n",
      "Noise folder:  noise_100,outliers_varied\n",
      "P shape (363, 363)\n",
      "s shape (363, 363)\n",
      "Noise folder:  noise_400,outliers_varied\n",
      "P shape (383, 383)\n",
      "s shape (383, 383)\n",
      "Noise folder:  noise_700,outliers_varied\n",
      "P shape (394, 394)\n",
      "s shape (394, 394)\n",
      "Noise folder:  noise_1300,outliers_varied\n",
      "P shape (383, 383)\n",
      "s shape (383, 383)\n",
      "Noise folder:  noise_1000,outliers_varied\n",
      "P shape (402, 402)\n",
      "s shape (402, 402)\n"
     ]
    }
   ],
   "source": [
    "trials = np.sort(os.listdir(path_to_graph_folder))\n",
    "\n",
    "sigma = 200\n",
    "u_dim = 30 # dim for universe of nodes\n",
    "\n",
    "scores = {100:[],400:[],700:[],1000:[],1300:[]}\n",
    "\n",
    "for trial in trials:\n",
    "    \n",
    "    if float(trial) >= 0.0:\n",
    "        \n",
    "        print('trial: ', trial)\n",
    "\n",
    "        all_files = os.listdir(path_to_graph_folder+trial)\n",
    "\n",
    "        for folder in all_files:\n",
    "\n",
    "            if os.path.isdir(path_to_graph_folder+trial+'/'+ folder):\n",
    "\n",
    "                print('Noise folder: ',folder)\n",
    "\n",
    "                path_to_graphs = path_to_graph_folder + '/' + trial + '/' + folder+'/graphs/'\n",
    "                path_to_groundtruth_ref = path_to_graph_folder + '/' + trial +'/' + folder + '/permutation_to_ref_graph.gpickle'\n",
    "                path_to_groundtruth  = path_to_graph_folder + '/' + trial + '/' + folder + '/ground_truth.gpickle'\n",
    "\n",
    "\n",
    "                noise = folder.split(',')[0].split('_')[1]\n",
    "                graph_meta = GraphDataset(path_to_graphs, path_to_groundtruth_ref)\n",
    "                ground_truth =  nx.read_gpickle(path_to_groundtruth)   \n",
    "                res = get_permutation_matrix_from_dictionary(ground_truth, graph_meta.sizes)\n",
    "                \n",
    "\n",
    "                node_kernel = create_gaussian_node_kernel(sigma,'coord')\n",
    "                knode = create_full_node_affinity_matrix(graph_meta.list_graphs, node_kernel)\n",
    "                #s = np.eye(knode.shape[0], knode.shape[1])\n",
    "                path_init = path_to_graph_folder + '/'+ trial + '/' + folder + '/X_kmeans.mat'                \n",
    "                X_kmeans = sio.loadmat(path_init)\n",
    "                #u = X_kmeans['U']\n",
    "                s = X_kmeans['full_assignment_mat']\n",
    "\n",
    "                # Old Implementation\n",
    "#                 node_kernel = kern.create_node_kernel(sigma, \"coord\")   #Change coord to sphere_3dcoords for real data\n",
    "#                 knode = mm.create_full_node_affinity_matrix(graph_meta.list_graphs, node_kernel)\n",
    "#                 s, _ = utils.create_full_adjacency_matrix(graph_meta.list_graphs)\n",
    "#                 s = np.eye(knode.shape[0], knode.shape[1])\n",
    "#                 u = mm.hippi_multiway_matching(s, graph_meta.sizes, knode, u_dim)\n",
    "#                 P = u @ u.T\n",
    "\n",
    "                u = np.ones((s.shape[0], u_dim)) / u_dim + 1e-3 * np.random.randn(s.shape[0], u_dim)\n",
    "    \n",
    "            \n",
    "                U = hippi_multiway_matching(s, graph_meta.sizes, knode, u_dim)\n",
    "                P = U @ U.T\n",
    "\n",
    "                HiPPi_X = {}\n",
    "                HiPPi_X['full_assignment_mat'] = P\n",
    "                \n",
    "                print('P shape', P.shape)\n",
    "                print('s shape', s.shape)\n",
    "\n",
    "                sio.savemat(path_to_graph_folder + '/' + trial + '/' + folder + '/X_HiPPi.mat',HiPPi_X)\n",
    "\n",
    "                f1, prec, rec = matching.compute_f1score(P,res)\n",
    "\n",
    "                scores[int(noise)].append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{100: [0.15200918484500572,\n",
       "  0.14778947368421053,\n",
       "  0.16609783845278728,\n",
       "  0.16381933068102036],\n",
       " 400: [0.1680327868852459,\n",
       "  0.18726591760299627,\n",
       "  0.184394250513347,\n",
       "  0.13416815742397137],\n",
       " 700: [0.14322916666666666,\n",
       "  0.13772860690900882,\n",
       "  0.15698924731182798,\n",
       "  0.19256110520722636],\n",
       " 1000: [0.2282157676348548,\n",
       "  0.1827776445190693,\n",
       "  0.17051108095884213,\n",
       "  0.1598818814596077],\n",
       " 1300: [0.152885443583118,\n",
       "  0.14711033274956214,\n",
       "  0.1860873381610709,\n",
       "  0.1976301311891663]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.write_gpickle(scores,'Hippi_score.gpickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.ones((s.shape[0], u_dim)) / u_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
