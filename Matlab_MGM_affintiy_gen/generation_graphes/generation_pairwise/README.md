# Generation of simulated graphs and result of several pairwise graph matching algorithms on them

In this folder, one can find the code necessary to generate sulcal-pits like pairs of graph. It is also here that we provide the necessary script to compute affinity matrices and incidence matrices for all these graphs.

## Installation procedure

In order to run the above code, one need to be sure to have set the right environment. We recommend to use Anaconda to do so. The depedency are as follow (latest version runs on python 3.6):

numpy:
```sh
pip install numpy
```

networkx:
```sh
pip install networkx
```

trimesh:
```sh
pip install trimesh
```

slam:
slam is an layer that comes over trimesh and which is used to sample random points on the surface of a sphere. To use it, one first needs to clone the project from https://github.com/gauzias/slam . 
In order to make the conda environement recognize slam as an external module, one need to add a file named slam_path.pth (or any name with the extension .pth) in path/to/conda/envs/{env-name}/lib/pythonX.X/site-packages/ .  The .pth file contains one line of text that gives the absolute path to the slam module : "path/to/slam" 

## What kind of graphs are you creating ?
The idea is to create pairs of graphs that simulate well the structure of sulcal-pits graph. To do so, the first step is to sample n points from a sphere of radius 100. Then we use the convex hull represented by all these points to create the edge information of the graph. Each node gets as an attribute the corresponding coordinates on the sphere and the edge uses the geodesical distances between the two points they are attached to as attribute.

A second graph is created by taking the first graph and applying gaussian noise on the attributes of the first graph. Finally outliers points are created and randomly attached to close neighbors.

## How do you calculate the affinity matrices ?

In order to calculate the affinity matrices we use a gaussian kernel on the attributes of the node/edge that we are looking for : $exp(\gamma \lVert q_1 - q_2 \rVert^2_2)$. The variable gamma is inferred for each pair by taking the median of the distances between every pair of coordinates (or geodesic distances for the edges). 

## Description of the different files

### script_generation_graphs.py

This script is used to generate a set of pairs of graphs in a specified folder with different parameters to use. To use it one needs only to give a path to the directory where all the graphs will be created. However a set of optional parameters are here to help to change important parameters that one could find of importance :
* --nb_graphs : The number of graphs to generate per couple of parameters
* --nb_vertices : The original number of nodes for each graphs
* --min_noise: The minimum value for the noise parameter (which changes the deviation of the gaussian noise applied to the second graph)
* --max_noise: The maximum value for the noise parameter (in the sense of the range function, even if these values can be floats)
* --step_noise: The step size to go from min to max value of noise
* --min_outliers: The minimum number of outliers
* --max_outliers: The maximum number of outliers
* --step_outliers: The step size to go from min to max number of outliers

### script_generation_affinity_and_incidence_matrix.py
This script generates all the affinity matrices for the pairs of graph located in a given folder (generated by the generation graphs script). The only necessary argument is the path to the directory were are located the graphs. A gaussian kernel will be used and the gamma value will be inferred for each pair of graph as shortly described above. Here are the other optionnal arguments:
* --nb_workers: Decide on how many workers to launch in parallell. Each worker will generate the affinity matrices for a pair of graph.

### script_get_result_tensors.py
This script goes through the generated graphs, collects the matching of the different algorithms and calculate the accuracy compared to ground truth values. needs two argument : the path to the graph folder and a path to write the result from the calculation (it is serialized with pickle).

### jupyter notebooks
These files are here to help one understand the function that are used in the above scripts and to make it easy to play with the parameters. However the code provided in the notebooks may not be up to date and should not be used in real settings. If one wishes to generate graphs and affinity matrices he should only use the script mentionned above.

