{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle as p\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import networkx as nx\n",
    "import sys\n",
    "import slam.io as sio\n",
    "import networkx as nx\n",
    "import tools.graph_visu as gv\n",
    "import tools.graph_processing as gp\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import trimesh\n",
    "import slam.topology as stop\n",
    "from sphere import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sphere_random_sampling(vertex_number=100, radius=1.0):\n",
    "    \"\"\"\n",
    "    generate a sphere with random sampling\n",
    "    :param vertex_number: number of vertices in the output spherical mesh\n",
    "    :param radius: radius of the output sphere\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    coords = np.zeros((vertex_number, 3))\n",
    "    for i in range(vertex_number):\n",
    "        M = np.random.normal(size=(3, 3))\n",
    "        Q, R = np.linalg.qr(M)\n",
    "        coords[i, :] = Q[:, 0].transpose() * np.sign(R[0, 0])\n",
    "    if radius != 1:\n",
    "        coords = radius * coords\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tri_from_hull(vertices):\n",
    "    \"\"\"\n",
    "    compute faces from vertices using trimesh convex hull\n",
    "    :param vertices: (n, 3) float\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    mesh = trimesh.Trimesh(vertices=vertices, process=False)\n",
    "    return mesh.convex_hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noisy_graph(original_graph, nb_vertices, sigma_noise_nodes = 1, sigma_noise_edges = 1, radius = 100):\n",
    "    \n",
    "    # generate ground_truth permutation\n",
    "    ground_truth_permutation = np.random.permutation(nb_vertices)\n",
    "    #ground_truth_permutation = np.arange(nb_vertices)\n",
    "    \n",
    "    # create a new graph\n",
    "    noisy_graph = nx.Graph()\n",
    "\n",
    "    # add the nodes (not very clean but it works fine and run in no time)\n",
    "    for node_to_add in range(len(ground_truth_permutation)):\n",
    "        for original_node, current_node in enumerate(ground_truth_permutation):\n",
    "            if current_node == node_to_add:\n",
    "                print(original_node,node_to_add)\n",
    "                noisy_coordinate = original_graph.nodes[original_node][\"coord\"] + \\\n",
    "                    np.random.multivariate_normal(np.zeros(3), np.eye(3) * sigma_noise_nodes)\n",
    "\n",
    "                # We project on the sphere\n",
    "                noisy_coordinate = noisy_coordinate / np.linalg.norm(noisy_coordinate) * radius\n",
    "                noisy_graph.add_node(node_to_add, coord = noisy_coordinate)\n",
    "        \n",
    "    compute_noisy_edges = tri_from_hull(list(nx.get_node_attributes(noisy_graph,'coord').values())) # take all peturbated coord and comp conv hull.\n",
    "    adja = stop.edges_to_adjacency_matrix(compute_noisy_edges) # compute the new adjacency mat\n",
    "    edge_list = [tuple((u,v)) for u,v in zip(adja.nonzero()[0],adja.nonzero()[1])] # convert to edge list to add edge attributes.\n",
    "\n",
    "\n",
    "    # add the edges\n",
    "    for edge in edge_list:\n",
    "\n",
    "        # get the original and corresponding ends\n",
    "        #end_a_corresponding, end_b_corresponding = ground_truth_permutation[edge[0]], ground_truth_permutation[edge[1]]\n",
    "        coordinate_a, coordinate_b = noisy_graph.nodes[edge[0]][\"coord\"], noisy_graph.nodes[edge[1]][\"coord\"]\n",
    "\n",
    "        # calculate noisy geodesic distance\n",
    "        noisy_geodesic_dist = gp.compute_geodesic_distance_sphere(coordinate_a, coordinate_b, radius)\n",
    "\n",
    "        # Add the new edge to the graph\n",
    "        noisy_graph.add_edge(edge[0],edge[1], weight = 1.0, geodesic_distance = noisy_geodesic_dist)\n",
    "    \n",
    "    return ground_truth_permutation, noisy_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noisy_graph_2(original_graph, nb_vertices,nb_outliers,sigma_noise_nodes=1, sigma_noise_edges=1, radius=100):\n",
    "    # Perturbate the coordinates\n",
    "    # noisy_coord = [points+np.random.multivariate_normal(np.zeros(3), np.eye(3) * sigma_noise_nodes)\n",
    "    # \tfor points in list(nx.get_node_attributes(original_graph,'coord').values())]\n",
    "\n",
    "    ground_truth_permutation = np.arange(nb_vertices)\n",
    "    # create a new graph\n",
    "    noisy_graph = nx.Graph()\n",
    "    # add the nodes (not very clean but it works fine and run in no time)\n",
    "    for node_to_add in range(len(ground_truth_permutation)):\n",
    "        for original_node, current_node in enumerate(ground_truth_permutation):\n",
    "            if current_node == node_to_add:\n",
    "                # noisy_coordinate = original_graph.nodes[original_node][\"coord\"] + \\\n",
    "                # \tnp.random.multivariate_normal(np.zeros(3), np.eye(3) * sigma_noise_nodes)\n",
    "\n",
    "                # Sampling from Von Mises - Fisher distribution\n",
    "                original_coord = original_graph.nodes[original_node][\"coord\"]\n",
    "                mean_original = original_coord / np.linalg.norm(original_coord)  # convert to mean vector\n",
    "                noisy_coordinate = Sphere().sample(1, distribution='vMF', mu=mean_original,\n",
    "                                                   kappa=sigma_noise_nodes).sample[0]\n",
    "\n",
    "                #noisy_coordinate = noisy_coordinate / np.linalg.norm(noisy_coordinate) * radius\n",
    "                noisy_coordinate  = noisy_coordinate * np.linalg.norm(original_coord)\n",
    "                noisy_graph.add_node(node_to_add, coord=noisy_coordinate)\n",
    "                \n",
    "    noisy_coord = list(nx.get_node_attributes(noisy_graph, 'coord').values())\n",
    "                \n",
    "    # Add Outliers\n",
    "    if nb_outliers > 0:\n",
    "        print(\"nb_outliers: \",nb_outliers)\n",
    "        sphere_random_sampling = generate_sphere_random_sampling(vertex_number=nb_outliers, radius=radius)\n",
    "        # merge pertubated and outlier coordinates to add edges \n",
    "        all_coord = noisy_coord + list(sphere_random_sampling)\n",
    "    else:\n",
    "        all_coord = noisy_coord\n",
    "\n",
    "    print(\"nb_outliers: \",nb_outliers)\n",
    "\n",
    "\n",
    "    compute_noisy_edges = tri_from_hull(all_coord)  # take all peturbated coord and comp conv hull.\n",
    "    adja = stop.edges_to_adjacency_matrix(compute_noisy_edges)  # compute the new adjacency mat.\n",
    "\n",
    "    # Extracting the ground-truth correspondence\n",
    "    ground_truth_permutation = []\n",
    "    for ar1 in compute_noisy_edges.vertices.view(np.ndarray):\n",
    "        index = 0\n",
    "        for ar2 in noisy_coord:\n",
    "            if np.mean(ar1) == np.mean(ar2):\n",
    "                ground_truth_permutation.append(index)\n",
    "                index += 1\n",
    "                break\n",
    "            else:\n",
    "                index += 1\n",
    "                continue\n",
    "\n",
    "    print(\"Total Ground truth nodes: \", len(ground_truth_permutation))\n",
    "    print(\"Total number of nodes : \", len(compute_noisy_edges.vertices))\n",
    "\n",
    "    noisy_graph = nx.from_numpy_matrix(adja.todense())\n",
    "\n",
    "    node_attribute_dict = {}\n",
    "    for node in noisy_graph.nodes():\n",
    "        node_attribute_dict[node] = {\"coord\": np.array(compute_noisy_edges.vertices[node])}\n",
    "\n",
    "    nx.set_node_attributes(noisy_graph, node_attribute_dict)\n",
    "\n",
    "    nx.set_edge_attributes(noisy_graph, 1.0, name=\"weight\")\n",
    "\n",
    "    edge_attribute_dict = {}\n",
    "    id_counter = 0  # useful for affinity matrix caculation\n",
    "    for edge in noisy_graph.edges:\n",
    "        # We calculate the geodesic distance\n",
    "        end_a = noisy_graph.nodes()[edge[0]][\"coord\"]\n",
    "        end_b = noisy_graph.nodes()[edge[1]][\"coord\"]\n",
    "        geodesic_dist = gp.compute_geodesic_distance_sphere(end_a, end_b, radius)\n",
    "\n",
    "        # add the information in the dictionnary\n",
    "        edge_attribute_dict[edge] = {\"geodesic_distance\": geodesic_dist, \"id\": id_counter}\n",
    "        id_counter += 1\n",
    "\n",
    "    # add the edge attributes to the graph\n",
    "    nx.set_edge_attributes(noisy_graph, edge_attribute_dict)\n",
    "\n",
    "    return np.array(ground_truth_permutation), noisy_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noisy_graph_3(original_graph, nb_vertices,nb_outliers,sigma_noise_nodes=1, sigma_noise_edges=1, radius=100):\n",
    "    # Perturbate the coordinates\n",
    "    \n",
    "    noisy_coord = []\n",
    "    \n",
    "    for index in range(nb_vertices):\n",
    "        \n",
    "        # Sampling from Von Mises - Fisher distribution\n",
    "        original_coord = original_graph.nodes[index][\"coord\"]\n",
    "        mean_original = original_coord / np.linalg.norm(original_coord)  # convert to mean vector\n",
    "        noisy_coordinate = Sphere().sample(1, distribution='vMF', mu=mean_original,\n",
    "                                           kappa=sigma_noise_nodes).sample[0]\n",
    "\n",
    "        noisy_coordinate  = noisy_coordinate * np.linalg.norm(original_coord)\n",
    "        #print(noisy_coordinate)\n",
    "        noisy_coord.append(noisy_coordinate)\n",
    "                   \n",
    "    # Add Outliers\n",
    "    if nb_outliers > 0:\n",
    "        print(\"nb_outliers: \",nb_outliers)\n",
    "        sphere_random_sampling = generate_sphere_random_sampling(vertex_number=nb_outliers, radius=radius)\n",
    "        # merge pertubated and outlier coordinates to add edges \n",
    "        all_coord = noisy_coord + list(sphere_random_sampling)\n",
    "    else:\n",
    "        all_coord = noisy_coord\n",
    "\n",
    "    print(\"nb_outliers: \",nb_outliers)\n",
    "\n",
    "    noisy_graph = nx.Graph()\n",
    "\n",
    "    compute_noisy_edges = tri_from_hull(all_coord)  # take all peturbated coord and comp conv hull.\n",
    "    adja = stop.edges_to_adjacency_matrix(compute_noisy_edges)  # compute the new adjacency mat.\n",
    "    \n",
    "\n",
    "    # Extracting the ground-truth correspondence\n",
    "\n",
    "    noisy_graph = nx.from_numpy_matrix(adja.todense())\n",
    "\n",
    "    node_attribute_dict = {}\n",
    "    for node in noisy_graph.nodes():\n",
    "        node_attribute_dict[node] = {\"coord\": np.array(compute_noisy_edges.vertices[node])}\n",
    "\n",
    "    nx.set_node_attributes(noisy_graph, node_attribute_dict)\n",
    "\n",
    "    nx.set_edge_attributes(noisy_graph, 1.0, name=\"weight\")\n",
    "\n",
    "    edge_attribute_dict = {}\n",
    "    id_counter = 0  # useful for affinity matrix caculation\n",
    "    for edge in noisy_graph.edges:\n",
    "        # We calculate the geodesic distance\n",
    "        end_a = noisy_graph.nodes()[edge[0]][\"coord\"]\n",
    "        end_b = noisy_graph.nodes()[edge[1]][\"coord\"]\n",
    "        geodesic_dist = gp.compute_geodesic_distance_sphere(end_a, end_b, radius)\n",
    "\n",
    "        # add the information in the dictionnary\n",
    "        edge_attribute_dict[edge] = {\"geodesic_distance\": geodesic_dist, \"id\": id_counter}\n",
    "        id_counter += 1\n",
    "\n",
    "    # add the edge attributes to the graph\n",
    "    nx.set_edge_attributes(noisy_graph, edge_attribute_dict)\n",
    "\n",
    "    return noisy_graph,noisy_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gpickle(\"reference_0.gpickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_coord =  list(nx.get_node_attributes(G,'coord').values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0\n",
      "3 1\n",
      "13 2\n",
      "11 3\n",
      "4 4\n",
      "1 5\n",
      "2 6\n",
      "19 7\n",
      "10 8\n",
      "7 9\n",
      "16 10\n",
      "12 11\n",
      "18 12\n",
      "15 13\n",
      "6 14\n",
      "0 15\n",
      "5 16\n",
      "14 17\n",
      "17 18\n",
      "8 19\n"
     ]
    }
   ],
   "source": [
    "ground_truth_permutation_old, noisy_graph_old = generate_noisy_graph(G,len(original_coord),10,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17, 11, 13,  3,  7, 18, 10, 14,  1, 16, 19,  2,  0,  6, 15,  5,  8,\n",
       "        4,  9, 12])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_permutation_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-10.54193644,  78.78266841,  60.68079379]),\n",
       " array([ 10.8577999 , -90.23249159,  41.71577212]),\n",
       " array([ -7.1834572 , -97.59865898,  20.56452546]),\n",
       " array([-32.70926455,  74.32972311, -58.35405963]),\n",
       " array([-36.82839016,  12.96707269, -92.06261296])]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_graph_old_coord = list(nx.get_node_attributes(noisy_graph_old,'coord').values())\n",
    "noisy_graph_old_coord[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ground_truth_permutation_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground_truth_permutation, noisy_graph = generate_noisy_graph_2(G,len(original_coord),0,10000,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-37.2927128 ,  86.0338805 ,  34.74802121]),\n",
       " array([-27.01509615,  76.77730558, -58.0984503 ]),\n",
       " array([-79.12422892, -49.82797097, -35.44756279]),\n",
       " array([ 19.5355599 , -81.85231429,  54.02370355]),\n",
       " array([-11.06893283,  79.69635651,  59.37987441])]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_graph_coord = list(nx.get_node_attributes(noisy_graph,'coord').values())\n",
    "noisy_graph_coord[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  8, 10, 19,  5,  6,  4, 18,  9, 12, 11,  1,  3, 16,  7, 14, 15,\n",
       "       13, 17,  2])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 93.98085132,  11.29476111, -32.24946445]),\n",
       " array([-88.83753711, -24.01960081,  39.12736609]),\n",
       " array([74.81953047, 18.93880042, 63.58741777]),\n",
       " array([  8.42748697, -88.98509987,  44.84004308]),\n",
       " array([-29.58511839,   7.77831689, -95.2061897 ])]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_coord[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-35.51803649,  86.10340222,  36.39606036])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_coord[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ground_truth_permutation_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_coord = noisy_graph_coord\n",
    "random.shuffle(shuffled_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_noisy_edges = tri_from_hull(noisy_graph_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_outliers:  0\n"
     ]
    }
   ],
   "source": [
    "noisy_graph_3,noisy_coord_3 = generate_noisy_graph_3(G,len(original_coord),0,10000,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_sequence = []\n",
    "\n",
    "for ar1 in noisy_coord_3:\n",
    "    \n",
    "    for i in range(len(noisy_graph_3.nodes)):\n",
    "        \n",
    "        if np.mean(ar1) == np.mean(noisy_graph_3.nodes[i]['coord']):\n",
    "            \n",
    "            ground_truth_sequence.append(i)\n",
    "            break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 0, 2, 9, 11, 10, 13, 18, 17, 7, 12, 1, 6, 3, 16, 4, 8, 19, 5, 15]"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_G = noisy_graph_3.copy()\n",
    "\n",
    "mapping = dict(zip(ground_truth_sequence,list(test_G.nodes)))\n",
    "\n",
    "test_G = nx.relabel_nodes(test_G, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-35.69382236,  86.21730164,  35.95174465])"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_G.nodes[19]['coord']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-35.69382236,  86.21730164,  35.95174465])"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_coord_3[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
